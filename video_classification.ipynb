{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3vZXr5pBFqntHfRwITakj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/Hugging-Face/blob/main/video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Video Classification"
      ],
      "metadata": {
        "id": "9k54J3lcrGLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2j4_jMsRHN4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install pytorchvideo transformers evaluate"
      ],
      "metadata": {
        "id": "YNPieMyRHN-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrUYiP_DHOD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from huggingface_hub import notebook_login, hf_hub_download\n",
        "import tarfile\n",
        "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification, TrainingArguments, Trainer, pipeline\n",
        "import pytorchvideo.data\n",
        "from pytorchvideo.transforms import ApplyTransformToKey, Normalize, RandomShortSideScale, RemoveKey, ShortSideScale, UniformTemporalSubsample\n",
        "from torchvision.transforms import Compose, Lambda, RandomCrop, RandomHorizontalFlip, Resize\n",
        "import imageio\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "logVeQAVHOJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iKhGSwQetEku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset_identifier = \"sayakpaul/ufc101-subset\"\n",
        "filename = \"UFC101_subset.tar.gz\"\n",
        "file_path = hf_hub_download(repo_id=hf_dataset_identifier,filename=filename,repo_type=\"dataset\")\n"
      ],
      "metadata": {
        "id": "hSsuzacytErM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hSqlx9aYtE15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(file_path) as t:\n",
        "    t.extractall(\".\")"
      ],
      "metadata": {
        "id": "w5coCyW-tE9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9CuAqrBttFDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = sorted({str(path).split(\"/\")[2] for path in all_video_file_paths})\n",
        "label2id = {label:i for i, label in enumerate(class_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "print(f\"Unique classes: {list(label2id.keys())}.\")\n"
      ],
      "metadata": {
        "id": "qhsUotMGtFJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hWdlLNtFtFQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"MCG-NJU/videomae-base\"\n",
        "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
        "model = VideoMAEForVideoClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "2nR15vPLtFXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M4gL6AnrtFdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = image_processor.image_mean\n",
        "std = image_processor.image_std\n",
        "if \"shortest_edge\" in image_processor.size:\n",
        "    height = width = image_processor.size[\"shortest_edge\"]\n",
        "else:\n",
        "    height = image_processor.size[\"height\"]\n",
        "    width = image_processor.size[\"width\"]\n",
        "resize_to = (height,width)\n",
        "num_frames_to_sample = model.config.num_frames\n",
        "sample_rate = 4 \n",
        "fps = 30 \n",
        "clip_duration = num_frames_to_sample * sample_rate / fps\n"
      ],
      "metadata": {
        "id": "nW_ATSKMtFjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gnkeU0LZSBnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def"
      ],
      "metadata": {
        "id": "xeHhDTiGSCh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xP-AayLwSCr_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BxUvUF7OSC02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mmq-hBhgSC7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHBfFLxqSDDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wAoLyS0qSDLA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNonm0JlSDSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hT60Am0SBsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unnormalize_img():"
      ],
      "metadata": {
        "id": "J4D5mef7sxKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nmy0mfW-TTs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gif():"
      ],
      "metadata": {
        "id": "Ic4wbWg2TT0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q7LKhd9ETT6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_gif():\n",
        "  "
      ],
      "metadata": {
        "id": "1EIYrl09TUAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3D2Nbb1ZTUGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video = next(iter(train_dataset))\n",
        "video_tensor = sample_video[\"video\"]\n",
        "display_gif(video_tensor)"
      ],
      "metadata": {
        "id": "jvxCyCtOTUMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ij8zNRKnTUS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "new_model_name = f\"{model_name}-finetuned-ucf101-subset\"\n",
        "num_epochs = 4\n",
        "args = TrainingArguments(\n",
        "    new_model_name,\n",
        "    remove_unused_columns=,\n",
        "    evaluation_strategy,\n",
        "    save_strategy,\n",
        "    learning_rate,\n",
        "    per_device_train_batch_size,\n",
        "    per_device_eval_batch_size,\n",
        "    warmup_ratio,\n",
        "    logging_steps,\n",
        "    load_best_model_at_end,\n",
        "    metric_for_best_model,\n",
        "    push_to_hub,\n",
        "    max_steps\n",
        ")"
      ],
      "metadata": {
        "id": "SVb39UB4TUZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UcoCUrhUTwaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load()\n",
        "def compute_metrics():\n",
        "    predictions = np.argmax(eval_pred.predictions,axis=1)\n",
        "    return metric.compute(predictions = predictions, references = eval_pred.label_ids)\n",
        "    "
      ],
      "metadata": {
        "id": "gAP37aC3Twha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jHupiwEqTwpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn():\n",
        "    pixel_values = torch.stack(\n",
        "        [example[\"video\"].permute(1,0,2,3) for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values,\"labels\":labels}"
      ],
      "metadata": {
        "id": "66lSIdXbTwvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VPdegT28Tw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset,\n",
        "    eval_dataset,\n",
        "    tokenizer,\n",
        "    compute_metrics,\n",
        "    data_collator)"
      ],
      "metadata": {
        "id": "RZT_qSvdTxGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_6EL6RW2TxPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()"
      ],
      "metadata": {
        "id": "l5r0w690TxXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0dguBIO5VoDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "9n3C6ufqVoKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ad8FqM0xVoQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_cls = pipeline(model=\"my_awesome_video_cls_model\")\n",
        "video_cls(\"https://huggingface.co/datasets/sayakpaul/ucf101-subset/resolve/main/v_BasketballDunk_g14_c06.avi\")\n"
      ],
      "metadata": {
        "id": "GzuVzZj4VoWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "syOjwB5fVocI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference():\n",
        "    permuted_sample_test_video = video.permute(1,0,2,3)\n",
        "    inputs = {\n",
        "        \"pixel_values\": permuted_sample_test_video.unsqueeze(0),\n",
        "        \"labels\": torch.tensor(\n",
        "            [sample_test_video[\"label\"]]\n",
        "        )\n",
        "    }\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda_is_available() else \"cpu\")\n",
        "    inputs = {k: v.to(device) for k,v in inputs.items()}\n",
        "    model = model.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "tC1jqTreVoh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EbclzoQ6Voz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = run_inference(trained_model,sample_test_video[\"video\"])"
      ],
      "metadata": {
        "id": "gZM2Bf4gVpIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t3A3xUcHVpQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"predicted class:\", model.config.id2label[predicted_class_idx])\n"
      ],
      "metadata": {
        "id": "1MU_o_wrVpXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pBveJsaUVpdw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rh4VCE4RVplS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}